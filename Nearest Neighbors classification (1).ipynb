{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dd09fc",
   "metadata": {},
   "source": [
    "# 第七章 K近邻算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75788ca1",
   "metadata": {},
   "source": [
    "# 1.K近邻算法葡萄酒数据集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74419242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.regression import KNNRegressionModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "#from pyspark.mllib.classification import KNNClassificationModel, KNNModel\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.sql.functions import concat, array, col\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#from pyspark.ml.classification import KNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50059ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae71c9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----+\n",
      "|原始样本|酒精含量(%)|苹果酸含量(%)|分类|\n",
      "+--------+-----------+-------------+----+\n",
      "|   样本1|          5|            2|   0|\n",
      "|   样本2|          6|            1|   0|\n",
      "|   样本3|          4|            1|   0|\n",
      "|   样本4|          8|            3|   1|\n",
      "|   样本5|         10|            2|   1|\n",
      "+--------+-----------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a spark session\n",
    "spark = SparkSession.builder.appName(\"KMeans\").getOrCreate()\n",
    "\n",
    "# load the data\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"葡萄酒.csv\")\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a151d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----+\n",
      "|原始样本|酒精含量(%)|苹果酸含量(%)|分类|\n",
      "+--------+-----------+-------------+----+\n",
      "|   样本1|        5.0|          2.0|   0|\n",
      "|   样本2|        6.0|          1.0|   0|\n",
      "|   样本3|        4.0|          1.0|   0|\n",
      "|   样本4|        8.0|          3.0|   1|\n",
      "|   样本5|       10.0|          2.0|   1|\n",
      "+--------+-----------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#强制类型转化，避免assembler中两特征值类型不同\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "data = data.withColumn(\"酒精含量(%)\", col(\"酒精含量(%)\").cast(DoubleType()))\n",
    "data = data.withColumn(\"苹果酸含量(%)\", col(\"苹果酸含量(%)\").cast(DoubleType()))\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e671d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----+----------+\n",
      "|原始样本|酒精含量(%)|苹果酸含量(%)|分类|  features|\n",
      "+--------+-----------+-------------+----+----------+\n",
      "|   样本1|        5.0|          2.0|   0| [5.0,2.0]|\n",
      "|   样本2|        6.0|          1.0|   0| [6.0,1.0]|\n",
      "|   样本3|        4.0|          1.0|   0| [4.0,1.0]|\n",
      "|   样本4|        8.0|          3.0|   1| [8.0,3.0]|\n",
      "|   样本5|       10.0|          2.0|   1|[10.0,2.0]|\n",
      "+--------+-----------+-------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成特征向量\n",
    "assembler = VectorAssembler(inputCols=[\"酒精含量(%)\",\"苹果酸含量(%)\"], outputCol=\"features\")\n",
    "\n",
    "data = assembler.transform(data)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f08e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练KNN模型\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13040a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------+----------+\n",
      "|酒精含量(%)|苹果酸含量(%)| features|prediction|\n",
      "+-----------+-------------+---------+----------+\n",
      "|          7|            1|[7.0,1.0]|         0|\n",
      "+-----------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 预测单个样本\n",
    "new_data1 = [(7,1)]\n",
    "test1 = spark.createDataFrame(new_data1,[\"酒精含量(%)\",\"苹果酸含量(%)\"])\n",
    "test1 = assembler.transform(test1)\n",
    "predictions = model.transform(test1)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5440f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------+----------+\n",
      "|酒精含量(%)|苹果酸含量(%)| features|prediction|\n",
      "+-----------+-------------+---------+----------+\n",
      "|          7|            1|[7.0,1.0]|         0|\n",
      "|          8|            3|[8.0,3.0]|         1|\n",
      "+-----------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#预测多个样本\n",
    "new_data2 = [(7,1),(8,3)]\n",
    "test2 = spark.createDataFrame(new_data2,[\"酒精含量(%)\",\"苹果酸含量(%)\"])\n",
    "test2 = assembler.transform(test2)\n",
    "predictions = model.transform(test2)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d222ce4",
   "metadata": {},
   "source": [
    "# 2.数据归一化代码演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b0bfd",
   "metadata": {},
   "source": [
    "2.1 min-max标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0a0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc72b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----+\n",
      "|原始样本|酒精含量(%)|苹果酸含量(%)|分类|\n",
      "+--------+-----------+-------------+----+\n",
      "|   样本1|         50|            2|   0|\n",
      "|   样本2|         60|            1|   0|\n",
      "|   样本3|         40|            1|   0|\n",
      "|   样本4|         80|            3|   1|\n",
      "|   样本5|        100|            2|   1|\n",
      "+--------+-----------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a spark session\n",
    "spark = SparkSession.builder.appName(\"Min-Max\").getOrCreate()\n",
    "# Create a DataFrame with some sample data\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"葡萄酒2.csv\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5177bb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----+\n",
      "|原始样本|酒精含量(%)|苹果酸含量(%)|分类|\n",
      "+--------+-----------+-------------+----+\n",
      "|   样本1|       50.0|          2.0|   0|\n",
      "|   样本2|       60.0|          1.0|   0|\n",
      "|   样本3|       40.0|          1.0|   0|\n",
      "|   样本4|       80.0|          3.0|   1|\n",
      "|   样本5|      100.0|          2.0|   1|\n",
      "+--------+-----------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumn(\"酒精含量(%)\", col(\"酒精含量(%)\").cast(DoubleType()))\n",
    "data = data.withColumn(\"苹果酸含量(%)\", col(\"苹果酸含量(%)\").cast(DoubleType()))\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c4a330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----+-----------+\n",
      "|原始样本|酒精含量(%)|苹果酸含量(%)|分类|   features|\n",
      "+--------+-----------+-------------+----+-----------+\n",
      "|   样本1|       50.0|          2.0|   0| [50.0,2.0]|\n",
      "|   样本2|       60.0|          1.0|   0| [60.0,1.0]|\n",
      "|   样本3|       40.0|          1.0|   0| [40.0,1.0]|\n",
      "|   样本4|       80.0|          3.0|   1| [80.0,3.0]|\n",
      "|   样本5|      100.0|          2.0|   1|[100.0,2.0]|\n",
      "+--------+-----------+-------------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成特征向量\n",
    "assembler = VectorAssembler(inputCols=[\"酒精含量(%)\",\"苹果酸含量(%)\"], outputCol=\"features\")\n",
    "\n",
    "data = assembler.transform(data)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b124cb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(scaledFeatures=DenseVector([0.1667, 0.5])),\n",
       " Row(scaledFeatures=DenseVector([0.3333, 0.0])),\n",
       " Row(scaledFeatures=DenseVector([0.0, 0.0])),\n",
       " Row(scaledFeatures=DenseVector([0.6667, 1.0])),\n",
       " Row(scaledFeatures=DenseVector([1.0, 0.5]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Fit the scaler to the data\n",
    "scalerModel = scaler.fit(data)\n",
    "\n",
    "# Transform the data using the scaler\n",
    "scaledData = scalerModel.transform(data)\n",
    "\n",
    "# Show the scaled data\n",
    "scaledData.select(\"scaledFeatures\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a1cc90",
   "metadata": {},
   "source": [
    "2.2 Z-score标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f880e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eaab051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(scaledFeatures=DenseVector([-0.6644, 0.239])),\n",
       " Row(scaledFeatures=DenseVector([-0.2491, -0.9562])),\n",
       " Row(scaledFeatures=DenseVector([-1.0796, -0.9562])),\n",
       " Row(scaledFeatures=DenseVector([0.5813, 1.4343])),\n",
       " Row(scaledFeatures=DenseVector([1.4118, 0.239]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withMean=True, withStd=True)\n",
    "\n",
    "# Fit the scaler to the data\n",
    "scalerModel = scaler.fit(data)\n",
    "\n",
    "# Transform the data using the scaler\n",
    "scaledData = scalerModel.transform(data)\n",
    "\n",
    "# scaledData = scaler.fit(data).transform(data)\n",
    "# Show the scaled data\n",
    "#scaledData.show()\n",
    "scaledData.select(\"scaledFeatures\").head(5)\n",
    "# scalerModel.mean, scalerModel.std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91088e61",
   "metadata": {},
   "source": [
    "因为原数据并非正态分布，故z-score标准化需要设置参数withMean=True, withStd=True\n",
    "\n",
    "当标准化结果不理想时，可以对原始数据进行一些预处理，例如去除异常值或进行平滑处理，也可以尝试使用其他的机器学习算法，例如决策树或者支持向量机等。\n",
    "\n",
    "由上述结果可以看出，此处的标准化结果与所给样例不同，猜想是因为sklearn库与StandardScaler标准差使用的公式不同。   \n",
    "\n",
    "在sklearn中公式如下：   \n",
    "$$\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_i-\\mu)^2}$$\n",
    "但在StandardScaler方法中为：  \n",
    "$$\\sigma = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(x_i-\\mu)^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74434bb4",
   "metadata": {},
   "source": [
    "# 3.案例实战 - 手写数字识别模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6e6cc",
   "metadata": {},
   "source": [
    "由于mlib中并未实现KNN方法，故使用KMeans进行替代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "995c649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"HandWriting\").getOrCreate()\n",
    "\n",
    "# 1.读取数据\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"手写字体识别.csv\")\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2e9fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=list(data.columns[1:]), outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "#手动生成特征向量：\n",
    "# columns_connect = [str(i) for i in range(1, 1024)]\n",
    "# data = data.select(*(col(c).cast(\"double\").alias(c) for c in data.columns))\n",
    "# data = data.withColumn(\"features\", array(*columns_connect))\n",
    "\n",
    "data = data.select(\"对应数字\",\"features\").dropna()\n",
    "#data.select(\"features\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e18a3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.划分训练集与测试集\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5baf0bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|对应数字|            features|\n",
      "+--------+--------------------+\n",
      "|       0|(1024,[8,9,10,11,...|\n",
      "|       0|(1024,[9,10,11,12...|\n",
      "|       0|(1024,[10,11,12,1...|\n",
      "|       0|(1024,[10,11,12,1...|\n",
      "|       0|(1024,[10,11,12,1...|\n",
      "|       0|(1024,[10,11,12,4...|\n",
      "|       0|(1024,[10,11,41,4...|\n",
      "|       0|(1024,[10,11,42,4...|\n",
      "|       0|(1024,[10,15,16,1...|\n",
      "|       0|(1024,[10,19,20,4...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "|       0|(1024,[11,12,13,1...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d249027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.训练KNN模型\n",
    "#由于是聚类方法，因此K必须为10类\n",
    "kmeans = KMeans().setK(10).setSeed(6)\n",
    "model = kmeans.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15c9a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.预测测试数据集结果\n",
    "from pyspark.sql.functions import concat_ws\n",
    "predictions = model.transform(trainingData)\n",
    "\n",
    "# predictions = predictions.select(col(\"对应数字\",\"prediction\").cast(\"string\"))\n",
    "# predictions.write.format(\"text\").save(\"数字对应分类\")\n",
    "\n",
    "predictions = predictions.withColumn(\"selected_columns\", concat_ws(\",\", *[col(c) for c in [\"对应数字\",\"prediction\"]]))\n",
    "predictions.select(\"selected_columns\").write.format(\"text\").save(\"数字对应分类2\")\n",
    "\n",
    "# predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63790250",
   "metadata": {},
   "source": [
    "将训练结果进行打印，得到每个数字对应的分类如下：  \n",
    "\n",
    "| 对应数字 | 聚类结果 |\n",
    "| -------- | -------- |\n",
    "| 0 | 4 |\n",
    "| 1 | 3 |\n",
    "| 2 | 2 | \n",
    "| 3 | 1 |\n",
    "| 4 | 0 |\n",
    "| 5 | 9 | \n",
    "| 6 | 8 | \n",
    "| 7 | 6 |\n",
    "| 8 | 5 |\n",
    "| 9 | 7 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2683f3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictions.show()\n",
    "#6.对测试集进行训练\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74b04677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(对应数字=0, prediction=5),\n",
       " Row(对应数字=0, prediction=5),\n",
       " Row(对应数字=0, prediction=5),\n",
       " Row(对应数字=0, prediction=5),\n",
       " Row(对应数字=0, prediction=5)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对比预测结果\n",
    "predictions.select(\"对应数字\",\"prediction\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5431aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|对应数字|count|\n",
      "+--------+-----+\n",
      "|       1|   48|\n",
      "|       6|   35|\n",
      "|       3|   31|\n",
      "|       5|   33|\n",
      "|       9|   45|\n",
      "|       4|   34|\n",
      "|       8|   34|\n",
      "|       7|   34|\n",
      "|       2|   37|\n",
      "|       0|   50|\n",
      "+--------+-----+\n",
      "\n",
      "+--------+----------+-----+\n",
      "|对应数字|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       3|         1|   29|\n",
      "|       2|         2|   35|\n",
      "|       8|         9|   12|\n",
      "|       9|         4|    5|\n",
      "|       8|         3|   14|\n",
      "|       1|         7|    2|\n",
      "|       1|         2|    1|\n",
      "|       4|         0|   22|\n",
      "|       0|         5|   49|\n",
      "|       5|         7|    6|\n",
      "|       6|         8|   35|\n",
      "|       4|         9|    1|\n",
      "|       9|         7|   36|\n",
      "|       1|         3|   30|\n",
      "|       0|         0|    1|\n",
      "|       1|         4|   15|\n",
      "|       8|         1|    1|\n",
      "|       4|         3|    1|\n",
      "|       2|         1|    1|\n",
      "|       4|         6|    3|\n",
      "|       8|         7|    6|\n",
      "|       8|         2|    1|\n",
      "|       3|         9|    1|\n",
      "|       5|         1|    1|\n",
      "|       9|         9|    1|\n",
      "|       4|         4|    7|\n",
      "|       9|         6|    3|\n",
      "|       3|         7|    1|\n",
      "|       5|         9|   26|\n",
      "|       2|         7|    1|\n",
      "|       7|         6|   34|\n",
      "+--------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7.对预测准确度进行评估\n",
    "\n",
    "#各数字\n",
    "predictions.groupBy(\"对应数字\").count().show()\n",
    "predictions.groupBy(\"对应数字\",\"prediction\").count().show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1204842",
   "metadata": {},
   "source": [
    "由各数字在测试集中出现次数与聚类结果进行比对，正确率计算如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c00567a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.797927\n"
     ]
    }
   ],
   "source": [
    "accuracy = (49+30+35+29+22+26+35+34+12+36)/(51+42+42+34+36+36+36+33+32+44)\n",
    "print(\"Test accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f46776",
   "metadata": {},
   "source": [
    "# 4.补充知识点：图像识别原理详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb27210",
   "metadata": {},
   "source": [
    "4.1 图片大小调整及显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee45b124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAACrElEQVR4nN2WPUgjQRTH35v9yK4aEXUREVPcQbDQUrAQbC1UbAJ6V3lXC3dgZWcfe4MIZzrJGWxUlPRaWIvaRPREAkEQbjf7NfOuSPAjrpuNxuaGaXY+3u/Nf/a9N0hE8JGNfaj1/wIgN7Va3N7a+/u8WGRdXcroqDo+DqyBixj9kv3z8/vFRX51BYwBETCmz8x0rKygqobsiiwR52Y6za+vsa0NNQ11HVW1ks87Ozvh+6ICnELBOTpCXX8cQgRZtg8PIVSDSAAyTSuTQcS6cZQkUSqR47wXYOfz3tkZKAoAPPMXETgHId4FEOWytbmJVeucq2NjqKrhsjQHqGSz/OYGJAk4Z319eipFnEe03hjAi8VKLoexGACQ62qzsyyRAN9vGcDKZMT9PTAGQrDeXj2VAs+Lbr0BwDs5sQ8Oau47jjY9zQyjKfdDAZyba2vkuoAIQrDubn1+vinTDQBOoeAeHz+qPzkpDQ62DECVirW+DtXIEoLF4/qXr2+w/irA/r3tnZ5W/33yPG1qSvr8qTpVPdNjQ0RNCwEEpGtRLlubv2qRBYCKArGYvb1d/eR/bp5aJ9OsbG0pw8PyyEggICBdm+m0ubHxNK+R58FDcDH2LD8TkeOgrHT8/KEvLLwE1Esk7u7s3d26FI+KgppW63XZvyoRiUouR7bdGAC+T64bPdXUjiEEKApgwI3WDzHDaJubA0ki1wXPC+h1gUYErss6O9u/fcdYQGkLLpn+xYUoleBFAQAAfnn5d3UVAGoB2NMTX16WhoakgYHAwwUXfTmZhGQycIobBiDWNCRCTVMnJkB+9fHQ9LOFXkhErhuyvvl30YP7T0daCGCGgfE4OQ74PlmWlEiER3IT76KH5uztWdksmabU39++tCS/cltvBwDUpK/PS60ERG7/AKoqMDmPIZcdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0xFFFE6D150748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAACrElEQVR4nN2WPUgjQRTH35v9yK4aEXUREVPcQbDQUrAQbC1UbAJ6V3lXC3dgZWcfe4MIZzrJGWxUlPRaWIvaRPREAkEQbjf7NfOuSPAjrpuNxuaGaXY+3u/Nf/a9N0hE8JGNfaj1/wIgN7Va3N7a+/u8WGRdXcroqDo+DqyBixj9kv3z8/vFRX51BYwBETCmz8x0rKygqobsiiwR52Y6za+vsa0NNQ11HVW1ks87Ozvh+6ICnELBOTpCXX8cQgRZtg8PIVSDSAAyTSuTQcS6cZQkUSqR47wXYOfz3tkZKAoAPPMXETgHId4FEOWytbmJVeucq2NjqKrhsjQHqGSz/OYGJAk4Z319eipFnEe03hjAi8VKLoexGACQ62qzsyyRAN9vGcDKZMT9PTAGQrDeXj2VAs+Lbr0BwDs5sQ8Oau47jjY9zQyjKfdDAZyba2vkuoAIQrDubn1+vinTDQBOoeAeHz+qPzkpDQ62DECVirW+DtXIEoLF4/qXr2+w/irA/r3tnZ5W/33yPG1qSvr8qTpVPdNjQ0RNCwEEpGtRLlubv2qRBYCKArGYvb1d/eR/bp5aJ9OsbG0pw8PyyEggICBdm+m0ubHxNK+R58FDcDH2LD8TkeOgrHT8/KEvLLwE1Esk7u7s3d26FI+KgppW63XZvyoRiUouR7bdGAC+T64bPdXUjiEEKApgwI3WDzHDaJubA0ki1wXPC+h1gUYErss6O9u/fcdYQGkLLpn+xYUoleBFAQAAfnn5d3UVAGoB2NMTX16WhoakgYHAwwUXfTmZhGQycIobBiDWNCRCTVMnJkB+9fHQ9LOFXkhErhuyvvl30YP7T0daCGCGgfE4OQ74PlmWlEiER3IT76KH5uztWdksmabU39++tCS/cltvBwDUpK/PS60ERG7/AKoqMDmPIZcdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0xFFFE6D150748>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('数字4.png')\n",
    "img = img.resize((32,32))\n",
    "img.show()\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07393cdb",
   "metadata": {},
   "source": [
    "4.2 图片灰度处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "437be262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABVElEQVR4nK2TPUsDQRCG373bXfEriagB4QStRBA7wVgosdFabGz8V/4KUxoRzkKSIBg0pYKdH0XUYAhaXHK3uxZ33FduI4Jvtbvz7MzszA5RGC3jF/s/ADS1/2y2p1bWSHRAkkm+nLwTkNIx04SQlY8xzlnjWpdD654DgHmnsgGn6gc3u2420Hg2g1DZHno2hVxlSCgOXHYMObMttEC7xuBtFaUWqH4TldvxoAMebzncUl7oAHnmQk2XkVYItB4Y3I15LdA/J1ATu0P2EKg/mfA2FwAGAISHQNDunk0ByupABwBxrpaWAyBo9+kFByAEYFAAGNCDvXiIrxsKACbn3HfJVW0QB0S6PJCUxIF82fCEL7/S3uQ+S+SA125w460CqNzR4lzyFbCsYFEAoPi6ma5DKAEAKsrp74NTGB/IfjGqJBka3qbtzB5aIwAoL/4tM4CkfgBFAmnUUlPBOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0xFFFD70147080>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.convert('L')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2fe88d",
   "metadata": {},
   "source": [
    "4.3 图片二值化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acbd1ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 二值化处理\n",
    "import numpy as np\n",
    "img_new = img.point(lambda x: 0 if x > 128 else 1)\n",
    "arr = np.array(img_new)\n",
    "\n",
    "# 打印arr中的每一行\n",
    "for i in range(arr.shape[0]):\n",
    "    print(arr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283bed4",
   "metadata": {},
   "source": [
    "4.4 二维数组转一维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cd155fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_new = arr.reshape(1, -1)\n",
    "arr_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68dee3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(arr_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1301d",
   "metadata": {},
   "source": [
    "此时我们可以把这个处理过的图片“数字4”传入到我们上面训练好的KMeans模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbd8a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"array_to_dataframe\").getOrCreate()\n",
    "\n",
    "# assembler = VectorAssembler(inputCols=arr_new[:], outputCol=\"features\")\n",
    "# arr_new = assembler.transform(arr_new)\n",
    "\n",
    "# import pandas as pd\n",
    "test_data = [(Vectors.dense(arr_new[0]),)]\n",
    "test_df = spark.createDataFrame(test_data, [\"features\"])\n",
    "predictions = model.transform(test_df)\n",
    "#print('图片中的数字为：' + str(answer[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83e6d18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(prediction=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.select(\"prediction\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5426c4b",
   "metadata": {},
   "source": [
    "经过比对，发现0聚类对应的数字为4，因此分类正确"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
